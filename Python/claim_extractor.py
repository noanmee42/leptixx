import os
import logging
from typing import List

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏ –µ—ë —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
import langextract as lx
import langextract.data 

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –æ—à–∏–±–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ClaimExtractor:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π —á–µ—Ä–µ–∑ langextract"""
    
    def __init__(self, api_key: str = None):
        # 1. –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å –∫–ª—é—á –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∏–ª–∏ –∏–∑ —Å–∏—Å—Ç–µ–º—ã
        self.api_key = (
            api_key or 
            os.getenv('GEMINI_API_KEY') or 
            os.getenv('GOOGLE_API_KEY')
        )
        
        if not self.api_key:
            raise ValueError("‚ùå API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω! –í—Å—Ç–∞–≤—å—Ç–µ –µ–≥–æ –≤ –∫–æ–¥ –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        
        logger.info("‚úì ClaimExtractor –≥–æ—Ç–æ–≤")
    
    def extract(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        
        prompt = """
        Extract all verifiable claims and facts from the text.
        Split complex sentences into simple facts.
        """
        
        # –ü—Ä–∏–º–µ—Ä—ã –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —á–µ—Ä–µ–∑ —Å–ø–µ—Ü. –∫–ª–∞—Å—Å—ã, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞ 'dict' object
        examples = [
            lx.data.ExampleData(
                text="Moscow is the capital of Russia with 12 million people.",
                extractions=[
                    lx.data.Extraction(
                        extraction_class="claim",
                        extraction_text="Moscow is the capital of Russia",
                        attributes={"fact": "Moscow is the capital of Russia"}
                    ),
                    lx.data.Extraction(
                        extraction_class="claim",
                        extraction_text="12 million people",
                        attributes={"fact": "Population of Moscow is 12 million"}
                    )
                ]
            )
        ]
        
        try:
            # –í—ã–∑–æ–≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            # –û–Ω–∞ –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –ª–∏–±–æ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç AnnotatedDocument, –ª–∏–±–æ —Å–ø–∏—Å–æ–∫
            results = lx.extract(
                text_or_documents=text,
                prompt_description=prompt,
                examples=examples,
                model_id="gemini-3-flash-preview", 
                api_key=self.api_key
            )
            
            claims = []

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–∏—Å–æ–∫, –∞ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç (AnnotatedDocument)
            # –¥–µ–ª–∞–µ–º –µ–≥–æ —Å–ø–∏—Å–∫–æ–º, —á—Ç–æ–±—ã –Ω–∞—à –∫–æ–¥ –Ω–∏–∂–µ —Å—Ä–∞–±–æ—Ç–∞–ª –≤ –æ–±–æ–∏—Ö —Å–ª—É—á–∞—è—Ö
            if not isinstance(results, (list, tuple)) and not hasattr(results, '__iter__'):
                results = [results]

            for res in results:
                # –í –æ–±—ä–µ–∫—Ç–µ AnnotatedDocument –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ª–µ–∂–∞—Ç –≤ –ø–æ–ª–µ extractions
                if hasattr(res, 'extractions') and res.extractions:
                    for item in res.extractions:
                        # –ë–µ—Ä–µ–º —Ñ–∞–∫—Ç –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏–ª–∏ —Å–∞–º —Ç–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                        val = None
                        if item.attributes and 'fact' in item.attributes:
                            val = item.attributes['fact']
                        else:
                            val = item.extraction_text
                        
                        if val:
                            claims.append(val)
            
            return list(set(claims))

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ LangExtract: {e}")
            return []

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –≤—ã–∑–æ–≤–∞
def extract_claims(text: str, api_key: str = None) -> List[str]:
    return ClaimExtractor(api_key).extract(text)

if __name__ == "__main__":
    # –¢–µ–ø–µ—Ä—å –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–µ–Ω load_dotenv()
    extractor = ClaimExtractor()
    
    test_text = "Japan is an island country in East Asia. Its capital is Tokyo."
    print(f"--- –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ ---\n{test_text}\n")
    
    try:
        res = extractor.extract(test_text)
        print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(res)} —Ñ–∞–∫—Ç–æ–≤:")
        for i, c in enumerate(res, 1):
            print(f"{i}. {c}")
    except Exception as e:
        print(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")